
# 데이터셋 정보


- data: 데이터셋. shape: (N, 4)
- frames: 데이터셋에 존재하는 총 프레임

```python
frames = np.unique(data[:, 0]).toList()
```
data[:, 0]: N개의 행에서 첫 번째(Frame) 정보만 추출 shape: (N, 1)
np.unique(): 중복되는 원소 없이 존재하는 모든 데이터를 추출

- frame_data: 각 프레임 단위로 데이터를 배열로 변환 -> [[... frame 1 ...], [... frame 2 ...], ]

```python
idx == data[:, 0]
# idx와 data를 element-wise하게 비교하여 bool 배열로 변환
```


요약
영상이 1000프레임이라고 가정하면
16프레임씩 0~983프레임까지 슬라이딩하면서 16프레임씩 묶어서 데이터 처리 (약간 CNN의 Filter처럼)
각 묶음에서 보행자 데이터가 프레임마다 모두 존재하는 것(유효 보행자)만 추출. 만약 묶음에 유효 보행자가 없으면 제외
그러면 영상마다 (M, 2, 16)개의 보행자 경로 데이터가 나올 것 (M은 유효 묶음 수)
그리고 영상이 N개면 총 (N, M, 2, 16) 크기의 데이터가 생김
근데, 이미 16프레임 단위 경로로 분할했기 때문에 영상 간 관계성이 모호해짐
영상과 묶음을 하나로 합쳐서 (N*M, 2, 16) 크기의 텐서로 바꿈
그 텐서를 (N * M, 2, 8) x2로 분할해서 앞은 x(학습), 뒤는 y(정답) 데이터로 이용

이미지를 어떻게 이용해야 할 것이냐.
1) frame마다 이미지를 추출해서 벡터를 쓸 수 있음 -> 정확도는 올라가겠지만 양이 너무 많을 것 (N*M*8)개 이미지가 필요함
2) 각 Sequence마다 이미지를 추출해서 벡터로 쓸 수 있음 -> (N*M)개의 이미지만 있으면 됨
3) 각 영상 마다 이미지를 추출해서 벡터로 쓸 수 있ㅇ므 -> N개의 이미지만 있으면 됨

2, 3번 옵션은 사실상 성능 차이가 크지 않을 것 같음.

여기서 이미지를 추가한 것이 SoPhie 모델임. 이미지 벡터를 추출할 때 이용한 것은 VGG-19 모델이고.


# 인코더 파트부터 다시 보면 됨.